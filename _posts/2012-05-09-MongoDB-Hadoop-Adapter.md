---
layout: post
title: MongoDB的Hadoop适配器
category : MongoDB
tags : [MongoDB, hadoop]
---
{% include JB/setup %}

`MongoDB Hadoop Adapter`

[mongo-hadoop](https://github.com/mongodb/mongo-hadoop)是一个MongoDB的hadoop适配器，主要对MapReduce的input和output进行适配，方便在hadoop任务中以MongoDB最为输入和输出。

## input
input适配主要是使用`MongoInputFormat`对MongoDB输入进行分割，split逻辑如下：  
![MongoInputFormat](https://github.com/gengmzh/gengmzh.github.com/raw/master/_includes/MongoInputFormat.png)
<br>
相关参数：  

+ mongo.input.split.create_input_splits
	
	要不要对输入进行分割，false时将这个输入作为一个InputSplit，在`MongoConfig`中配置。
	
+ isSharded
	
	输入集合是否分片，直接在MongoDB中stats得到。
	
+ mongo.input.split.read_shard_chunks
	
	是否可以根据chunk创建InputSplit，在`MongoConfig`中配置。
	
+ mongo.input.split.read_from_shards
	
	是否可以根据shard创建InputSplit，在`MongoConfig`中配置。
	
+ mongo.input.split_size
	
	手动分割MongoDB输入时的块大小，单位M，在`MongoConfig`中配置。
	

**会有多少个mapper**  
我们知道以hdfs存储文件作为输入时，mapper的数量=文件块的数量。  
`The Hadoop MapReduce framework spawns one map task for each InputSplit generated by the InputFormat for the job.`  
同样以MongoDB作为输入时，mapper数量会与`MongoInputFormat`分割出的`MongInputSplit`数量一致。  

**mapper会再哪里运行**  
以hdfs作为输入时，通常mapper会在文件块所在的datanode上运行。以MongoDB作为输入时，由于数据没有驻留datanode那么mapper会在哪里运行呢？    
TODO

## output
output适配就更为简单了，直接使用`MongoOutputFormat`将MapReduce任务的输出存到MongoDB中即可，代码逻辑如下：  
![MongoOutputFormat](https://github.com/gengmzh/gengmzh.github.com/raw/master/_includes/MongoOutputFormat.png)  

## issues
**性能问题**  
在hadoop集群环境下直接操作MongoDB，性能瓶颈不可避免，除非MongoDB分片架构有和hadoop相当的规模，此时可以考虑批量导库方式。


## references
+ [mongo-hadoop](https://github.com/mongodb/mongo-hadoop)
+ [Hadoop Mapper](http://hadoop.apache.org/common/docs/r1.0.2/mapred_tutorial.html#Mapper)
